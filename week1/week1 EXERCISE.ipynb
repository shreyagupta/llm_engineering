{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6bf04f-bd59-4bf3-85e2-b34bafdf4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b293f562-abcf-4317-a798-d31535416bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a very patient and detail oriented CS teachers who can answer question an intermediate python ML scientist for code she does not understand. \\\n",
    "Give the answer in Markdown.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "def get_user_prompt(question_asked):\n",
    "    user_prompt = f\"Explain the code {question_asked} to me asked in as a question.\"\n",
    "    user_prompt += f\"For example if the question asked was this code: \\\"{question}\\\".\\\n",
    "Then explain what \\\"yield from\\\", and specifically what \\\"yield\\\" and \\\"get\\\" do. What can you tell about the data type\\\n",
    "of \\\"books\\\" from this line of code. And why are curly braces being used? What would be other alternatives? What if variable sizes were very large?\"\n",
    "    return user_prompt\n",
    "\n",
    "def stream_gpt_answer(user_question):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "           {\"role\":\"system\", \"content\":system_prompt},\n",
    "           {\"role\":\"user\", \"content\":get_user_prompt(user_question)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    response=\"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response+=chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1754be63-1376-49be-a3c3-a6b2349a2d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Let's break down the question about the code snippet step by step.\n",
       "\n",
       "### Code Explanation\n",
       "\n",
       "The line of code you provided is:\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "#### What Does This Code Do?\n",
       "\n",
       "1. **Set Comprehension**: \n",
       "   - The part `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension. It creates a set of unique authors from the list or collection `books`.\n",
       "\n",
       "2. **Processing Books**: \n",
       "   - The comprehension iterates over each `book` in the `books` variable (which we will discuss later). For each `book`, it calls the method `get(\"author\")` to retrieve the value associated with the key `\"author\"`.\n",
       "\n",
       "3. **Conditional Filtering**: \n",
       "   - The `if book.get(\"author\")` checks if the author exists. Only books that have a valid author will be included in the resulting set.\n",
       "\n",
       "4. **Yielding Values**: \n",
       "   - The `yield from` statement is used to yield each item from the set of authors one by one rather than yielding the entire set at once. This is useful in generator functions where maintaining state is important.\n",
       "\n",
       "### Understanding `yield from`\n",
       "\n",
       "- **`yield`**: \n",
       "  - `yield` is a keyword in Python that transforms a function into a generator, which means it can be paused and resumed. When `yield` is called, the function returns the value and saves its state, so it can continue later from where it left off.\n",
       "\n",
       "- **`yield from`**: \n",
       "  - `yield from` is specifically used to yield all values from an iterable. In this case, it yields each author from the set of unique authors one by one.\n",
       "\n",
       "### What Does `get` Do?\n",
       "\n",
       "- **`get` Method**: \n",
       "  - `get` is a method used on dictionaries in Python. It retrieves the value associated with the specified key; in this case, the key is `\"author\"`. If the key does not exist, it returns `None` (or a specified default value if provided).\n",
       "\n",
       "### Data Type of `books`\n",
       "\n",
       "- The variable `books` is expected to be a list (or another iterable collection) of dictionaries. Each dictionary likely represents a book with key-value pairs, where one of the keys is `\"author\"`.\n",
       "\n",
       "### Why Use Curly Braces?\n",
       "\n",
       "- **Curly Braces**:\n",
       "  - Curly braces `{}` denote a set in Python. This structure automatically ensures that duplicate authors are not included. Each author will be unique in the resulting set.\n",
       "\n",
       "### Alternatives to Using Sets\n",
       "\n",
       "- Instead of using `{}`, you could use `[]` for a list comprehension, but that would not prevent duplicates:\n",
       "\n",
       "  python\n",
       "  authors = [book.get(\"author\") for book in books if book.get(\"author\")]\n",
       "  \n",
       "\n",
       "- However, this would require additional steps to convert the list to a set if uniqueness is desired:\n",
       "\n",
       "  python\n",
       "  unique_authors = set(authors)\n",
       "  \n",
       "\n",
       "### Considerations for Large Variable Sizes\n",
       "\n",
       "- If the size of `books` is very large:\n",
       "  - Using a set comprehension is more memory-efficient than creating a list first because it avoids duplicates directly.\n",
       "  - The generator produced by `yield from` allows you to process items as they are requested rather than loading all authors into memory at once.\n",
       "  - This can significantly reduce memory usage, especially if not all authors need to be processed at one time.\n",
       "\n",
       "### Summary\n",
       "\n",
       "The code snippet utilizes a set comprehension to retrieve unique authors from a collection of books, filtering out any books without an author and then yielding each unique author one by one using `yield from`. The `get` method safely fetches the author information, and curly braces define the structure of the data as a set."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_gpt_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b17474-b4f6-4524-930f-c23c9fd3f6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d7e2d3f-b35d-4eb8-b199-2b2641e8aca4",
   "metadata": {},
   "source": [
    "# Get Llama 3.2 to answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c575487-ad7f-4ddc-b638-305ed67b1b02",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d4c7d85-50c7-439a-b686-d24c5d8d1e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e26daae-d345-43f7-b8bd-bc250ab02db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_ollama_via_openai_answer(user_question):\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "           {\"role\":\"system\", \"content\":system_prompt},\n",
    "           {\"role\":\"user\", \"content\":get_user_prompt(user_question)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    response=\"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response+=chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77d62773-42dc-44e2-8d31-473bbf60396f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Question**\n",
       "Please explain what this code does and why:\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "**Answer**\n",
       "\n",
       "This line of code uses a combination of Python features to extract the authors from a list of books. Let's break it down step by step.\n",
       "\n",
       "* `books`: This is the variable containing the list of books.\n",
       "* `{book.get(\"author\") for book in books if book.get(\"author\")}`: This is a **nested generator expression**. It uses the `.get()` method (more on that later) to filter and transform the data from the `books` list.\n",
       "\n",
       "Here's a simplified explanation:\n",
       "\n",
       "1. The outer loop iterates over each book in the `books` list.\n",
       "2. For each book, the inner expression:\n",
       "\t* Calls `book.get(\"author\")`, which returns the author name associated with that book (if it exists). This value is used to filter out books without an author (more on this filtering clause).\n",
       "\t* Uses dictionary comprehension to create a new generator expression containing only the authors from that book.\n",
       "\n",
       "The `(book.get(\"author\"))` part ensures `book.get(\"author\")` returns an empty string if no author name is found. This way, empty strings are not included in the output when filter out books with no author.\n",
       "\n",
       "**`yield from`**\n",
       "Now, let's talk about `yield from`. This is a new syntax introduced in Python 3.3 (and later). When used with a generator expression or another iterable, it allows us to delegate generation of values from one function to another.\n",
       "\n",
       "In this case:\n",
       "\n",
       "* The result of the nested generator expression `{...}` is an iterable containing the authors.\n",
       "* `yield from` says: \"instead of returning `this` iterable, *re-yield* each element of the given iterable\".\n",
       "\n",
       "**`get` method**\n",
       "The `.get()` method calls the dict (key-value pair dictionary) to retrieve a value associated with a specific key. It returns:\n",
       "\n",
       "* The **value** for that key if it exists in the dictionary.\n",
       "* A default value (`None`, the second argument) if no matching value is found.\n",
       "\n",
       "In this case, `book.get(\"author\")` returns an author's name or `None` if that book doesn't have one.\n",
       "\n",
       "**Data structure**\n",
       "The `books` variable contains a list of dictionaries. Each dictionary represents a book and has keys (`title`, `authors`, etc.) and values (such as the book's title, publication year, authors...).\n",
       "\n",
       "Here example:\n",
       "\n",
       "python\n",
       "books = [\n",
       "    {\"id\": 1, \"title\": \"Book A\", \"author\": \"John Smith\"},\n",
       "    {\"id\": 2, \"title\": \"Book B\",\n",
       "     \"author\": None},\n",
       "    {\"id\": 3, \"title\": \"Book C`, `author\": \"Jane Doon\"}\n",
       "]\n",
       "\n",
       "\n",
       "**Curly braces**\n",
       "The curly braces `{}` syntax creates a new iterable. In this case, we use it to define a nested generator expression.\n",
       "\n",
       "Other alternatives might be:\n",
       "\n",
       "* Using a list comprehension and then yielding from the resulting list.\n",
       "* Rewriting the generator expression using `map` functions or similar constructs.\n",
       "\n",
       "python\n",
       "# List comprehension:\n",
       "for author in {book['author'] for book in books if 'author' in book}:\n",
       "    yield author\n",
       "\n",
       "# Map function:\n",
       "from functools import partial\n",
       "yield from map(partial(dict.get, \"author\"), filter(None, books))\n",
       "\n",
       "\n",
       "**Performance**\n",
       "When working with very large datasets, using generator expressions and `yield` can be beneficial because it consumes less memory than creating lists or other data structures."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_ollama_via_openai_answer(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea5cd6-94ca-4a3f-9fa9-c93bae5193f1",
   "metadata": {},
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24efc022-a555-461f-98eb-9ae30cab8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_ollama_answer(user_question):\n",
    "    stream = ollama.chat(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "           {\"role\":\"system\", \"content\":system_prompt},\n",
    "           {\"role\":\"user\", \"content\":get_user_prompt(user_question)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    response=\"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response+=chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748a48b-3078-4ecd-addc-5f3af0e7dd86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
